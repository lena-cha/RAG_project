import os
import io
from typing import List, Tuple
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv

from pdfminer.high_level import extract_text

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS


# ----------------------------
# Page & Theme
# ----------------------------
st.set_page_config(
    page_title="AI in South Korea ğŸ‡°ğŸ‡· OpenAIâ€™s Economic Blueprint RAG Chat-bot",
    page_icon="ğŸ“Œ",
    layout="wide",
)

st.markdown(
    """
<style>
  .main { background: #f6fbf9; }
  .app-title {
    background: linear-gradient(90deg, #00704a, #2d8659);
    color: white; padding: 16px 24px; border-radius: 10px; font-weight: 700;
    display:flex; align-items:center; gap:10px; margin-bottom:16px;
  }
  .pill { display:inline-block; padding:2px 8px; border-radius:999px; background:#e8f5f0; color:#00704a; font-size:12px; margin-left:8px;}
  .card { background:white; padding:16px; border-radius:12px; border-left:4px solid #00704a; box-shadow:0 2px 6px rgba(0,0,0,0.06); color:#00704a; }
  .hint { color:#2d8659; font-size:13px; }
  .footer { text-align:center; color:#2d8659; margin-top:24px; }
</style>
""",
    unsafe_allow_html=True,
)

st.markdown(
    """
<div class="app-title">
  <span style="font-size:26px">[AI in South Korea] OpenAIâ€™s Economic Blueprint RAG Chat-bot</span>
  <span class="pill">LangChain Â· FAISS Â· OpenAI</span>
</div>
""",
    unsafe_allow_html=True,
)


# ----------------------------
# Helpers
# ----------------------------
def load_api_key() -> str:
    load_dotenv(override=False)
    api_key = os.getenv("OPENAI_API_KEY", "")
    if "openai_api_key" in st.session_state and st.session_state.openai_api_key:
        api_key = st.session_state.openai_api_key
    return api_key


def load_deploy_link() -> str:
    """Load deployed app URL from env or DEPLOY_LINK.txt at repo root."""
    link = os.getenv("STREAMLIT_DEPLOY_URL") or os.getenv("DEPLOY_URL") or ""
    if link:
        return link.strip()
    try:
        path = Path(__file__).resolve().parent.parent / "DEPLOY_LINK.txt"
        if path.exists():
            content = path.read_text(encoding="utf-8").strip()
            return content
    except Exception:
        pass
    return ""


def read_uploaded_file(file) -> Tuple[str, str]:
    """
    Returns (text, source_name)
    Supports PDF and TXT.
    """
    filename = file.name
    name_lower = filename.lower()
    raw_bytes = file.read()

    if name_lower.endswith(".pdf"):
        try:
            text = extract_text(io.BytesIO(raw_bytes))
        except Exception as e:
            raise RuntimeError(f"PDF íŒŒì‹± ì‹¤íŒ¨: {e}")
    elif name_lower.endswith(".txt"):
        try:
            text = raw_bytes.decode("utf-8", errors="ignore")
        except Exception:
            text = raw_bytes.decode("cp949", errors="ignore")
    else:
        raise RuntimeError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PDF ë˜ëŠ” TXTë§Œ ì—…ë¡œë“œí•˜ì„¸ìš”.")

    text = text.strip()
    if not text:
        raise RuntimeError("íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return text, filename


def chunk_documents(texts_with_sources: List[Tuple[str, str]], chunk_size: int, chunk_overlap: int) -> List[Document]:
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=["\n\n", "\n", " ", ""],
    )
    docs: List[Document] = []
    for text, source in texts_with_sources:
        for chunk in splitter.split_text(text):
            docs.append(Document(page_content=chunk, metadata={"source": source}))
    return docs


def build_vectorstore(docs: List[Document], api_key: str) -> FAISS:
    embeddings = OpenAIEmbeddings(api_key=api_key)
    vs = FAISS.from_documents(docs, embeddings)
    return vs


def format_context(docs: List[Document]) -> str:
    blocks = []
    for i, d in enumerate(docs, start=1):
        src = d.metadata.get("source", "unknown")
        blocks.append(f"[ë¬¸ì„œ {i}] (ì¶œì²˜: {src})\n{d.page_content}")
    return "\n\n".join(blocks)


def generate_answer(query: str, retrieved_docs: List[Document], api_key: str, model: str, temperature: float) -> str:
    context_text = format_context(retrieved_docs)
    system_prompt = (
        "ë‹¹ì‹ ì€ ì—…ë¡œë“œëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ëŠ” RAG ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
        "ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¥´ì„¸ìš”: 1) ë¬¸ì„œ ë‚´ìš©ì—ì„œ ê·¼ê±°ë¥¼ ì°¾ì•„ ìš”ì•½í•˜ì—¬ ë‹µë³€, 2) ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ê¸°, "
        "3) í•„ìš”í•˜ë©´ ê´€ë ¨ ê·¼ê±°ë¥¼ bulletë¡œ ì¸ìš©(íŒŒì¼ëª… í¬í•¨), 4) í—ˆêµ¬ ì •ë³´ ê¸ˆì§€."
    )

    user_prompt = (
        "ì§ˆë¬¸:\n" + query + "\n\n" +
        "ë‹¤ìŒì€ ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:\n\n" + context_text
    )

    llm = ChatOpenAI(model=model, temperature=temperature, api_key=api_key)
    res = llm.invoke([
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ])
    return res.content if hasattr(res, "content") else str(res)


# ----------------------------
# Sidebar Controls
# ----------------------------
with st.sidebar:
    st.markdown("### âš™ï¸ ì„¤ì •")
    api_key_input = st.text_input(
        "OpenAI API Key",
        type="password",
        placeholder="sk-...",
        help="í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY ë˜ëŠ” ì—¬ê¸° ì…ë ¥ (ì €ì¥ ì•ˆ ë¨)",
    )
    if api_key_input:
        st.session_state.openai_api_key = api_key_input

    model = st.selectbox("ëª¨ë¸", ["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini"], index=0)
    temperature = st.slider("ì°½ì˜ì„± (temperature)", 0.0, 1.0, 0.2, 0.1)
    chunk_size = st.slider("ì²­í¬ í¬ê¸°", 200, 2000, 800, 50)
    chunk_overlap = st.slider("ì²­í¬ ì¤‘ì²©", 0, 400, 120, 10)
    top_k = st.slider("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ (k)", 1, 10, 4, 1)

    st.markdown("---")
    clear_btn = st.button("ğŸ—‘ï¸ ì¸ë±ìŠ¤/ëŒ€í™” ì´ˆê¸°í™”")


# ----------------------------
# Session State
# ----------------------------
if clear_btn:
    for key in ["vectorstore", "docs_info", "messages"]:
        if key in st.session_state:
            del st.session_state[key]

if "messages" not in st.session_state:
    st.session_state.messages = []  # list of (role, content)


# ----------------------------
# Upload & Index Build
# ----------------------------
st.markdown("#### 1) ë¬¸ì„œ ì—…ë¡œë“œ")
st.markdown('<div class="card">PDF ë˜ëŠ” TXT íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.</div>', unsafe_allow_html=True)

uploads = st.file_uploader(
    "íŒŒì¼ ì—…ë¡œë“œ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
    type=["pdf", "txt"],
    accept_multiple_files=True,
)

api_key = load_api_key()

build_col1, build_col2 = st.columns([1, 3])
with build_col1:
    build_clicked = st.button("ğŸ§  ì¸ë±ìŠ¤ ìƒì„±/ê°±ì‹ ")
with build_col2:
    st.markdown("<span class=hint>ì—…ë¡œë“œ í›„ ì¸ë±ìŠ¤ ìƒì„± ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.</span>", unsafe_allow_html=True)

if build_clicked:
    if not api_key:
        st.error("OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì— ì…ë ¥í•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ ì„¤ì •í•˜ì„¸ìš”.")
    elif not uploads:
        st.error("ìµœì†Œ 1ê°œ ì´ìƒì˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        try:
            texts_with_sources: List[Tuple[str, str]] = []
            for f in uploads:
                text, src = read_uploaded_file(f)
                texts_with_sources.append((text, src))

            docs = chunk_documents(texts_with_sources, chunk_size, chunk_overlap)
            vs = build_vectorstore(docs, api_key)
            st.session_state.vectorstore = vs
            st.session_state.docs_info = {
                "num_files": len(uploads),
                "num_chunks": len(docs),
                "files": [f.name for f in uploads],
            }
            st.success("ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ! ì´ì œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
        except Exception as e:
            st.error(f"ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")


# ----------------------------
# Index Status
# ----------------------------
st.markdown("#### 2) ì¸ë±ìŠ¤ ìƒíƒœ")
status_container = st.container()
with status_container:
    if "vectorstore" in st.session_state:
        info = st.session_state.get("docs_info", {})
        st.markdown(
            f"- ì¸ë±ìŠ¤ ìƒíƒœ: âœ… ì¤€ë¹„ë¨  "+
            f"- íŒŒì¼ ìˆ˜: {info.get('num_files', 0)}  "+
            f"- ì²­í¬ ìˆ˜: {info.get('num_chunks', 0)}"
        )
        if info.get("files"):
            st.caption("ì—…ë¡œë“œ íŒŒì¼: " + ", ".join(info["files"]))
    else:
        st.markdown("- ì¸ë±ìŠ¤ ìƒíƒœ: â³ ì•„ì§ ìƒì„±ë˜ì§€ ì•ŠìŒ")


# ----------------------------
# Chat Interface
# ----------------------------
st.markdown("#### 3) ì±—ë´‡")
chat_container = st.container()

with chat_container:
    for role, content in st.session_state.messages:
        with st.chat_message(role):
            st.markdown(content)

    user_input = st.chat_input("ì—…ë¡œë“œí•œ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”â€¦")

    if user_input:
        if "vectorstore" not in st.session_state:
            st.error("ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        elif not api_key:
            st.error("OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            st.session_state.messages.append(("user", user_input))
            with st.chat_message("user"):
                st.markdown(user_input)

            try:
                retriever = st.session_state.vectorstore.as_retriever(search_kwargs={"k": top_k})
                # LangChain retrievers use .invoke() in recent versions
                retrieved_docs: List[Document] = retriever.invoke(user_input)

                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘â€¦"):
                    answer = generate_answer(user_input, retrieved_docs, api_key, model, temperature)

                with st.chat_message("assistant"):
                    st.markdown(answer)
                    with st.expander("ì°¸ì¡° ë¬¸ì„œ ë³´ê¸°"):
                        for i, d in enumerate(retrieved_docs, start=1):
                            src = d.metadata.get("source", "unknown")
                            st.markdown(f"**ë¬¸ì„œ {i}** Â· {src}")
                            st.write(d.page_content[:800] + ("â€¦" if len(d.page_content) > 800 else ""))

                st.session_state.messages.append(("assistant", answer))
            except Exception as e:
                err_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                with st.chat_message("assistant"):
                    st.error(err_msg)
                st.session_state.messages.append(("assistant", err_msg))


st.markdown("---")
st.markdown(
    "<div class=footer>Â© RAG Chatbot Demo Â· Streamlit Â· LangChain Â· FAISS</div>",
    unsafe_allow_html=True,
)


